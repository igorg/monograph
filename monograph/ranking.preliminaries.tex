Na área de \emph{aprendizado de máquina}, classificação é a tarefa de atribuir rótulos a cada elemento de um dado conjunto tendo como entrada pares elemento-rótulo. Comparativamente, \emph{ranking} é a tarefa de atribuir posições a cada elemento de um dado conjunto tendo como entrada pares elemento-rótulo, uma relação de ordem parcial entre os elementos, ou uma relação de ordem total entre os elementos \cite{tieyan09}.

Embora desempenhem tarefas diferentes com saídas diferentes, algoritmos de classificação e de \emph{ranking} podem compartilhar o mesmo tipo de entrada: pares elemento-rótulo. Isso é uma evidência de que se pode usar um algoritmo de classificação para compor um algoritmo de \emph{ranking}.

De fato, a técnica de \emph{ranking} descrita em \cite{langford08} propõe envolver  um algoritmo de classificação com etapas de pré-processamento e pós-processamento de forma que o produto final seja uma ordenação. Nesse estudo, essa técnica é chamada de \emph{ranking reduzido a classificação}.

\section{Introdução ao problema}

Dado um conjunto composto por elementos aos quais é possível atribuir um rótulo de valor $0$ ou $1$, deseja-se encontrar uma permutação dos elementos de maneira que os elementos que apresentem maior chance de receber o rótulo $0$ devem preceder os com maior chance de receber o rótulo $1$. Cada elemento é composto por um conjunto de características e a chance de um elemento receber o rótulo $0$ ou o rótulo $1$ deve ser calculada com base nessas características.

Substituindo-se a palavra rótulo pela palavra classe no enunciado anterior, percebe-se que o problema de ordenação pode ser tratado como um problema de classificação. Mais especificamente, um problema de classificação binária, pois os valores de classe possíveis são $0$ e $1$.

Um algoritmo de aprendizado para classificação recebe como entrada um conjunto em que cada elemento possui uma classe assinalada e, partindo dessa entrada, deve aprender um classificador capaz de atribuir uma classe a novos elementos. A etapa em que o aprendizado ocorre é chamada de treinamento.

O treinamento de um classificador é um aprendizado supervisionado, pois cada elemento submetido à etapa de treinamento está vinculado à sua classe verdadeira. Dessa forma, pode-se medir a qualidade do classificador aprendido usando elementos com classes conhecidas, porém suprimindo-as quando os elementos forem submetidos a classificação.

O produto da classificação de um elemento é uma previsão do valor da classe à qual aquele elemento pertence. Sobre a previsão é possível obter uma quantidade de certeza, ou probabilidade, do elemento pertencer à classe prevista. Nesso caso, por se tratar de um problema de classificação binária, se a probabilidade de um elemento pertencer à classe $0$ é $p$, então a probabilidade dele pertencer à classe $1$ é $1 - p$.

Uma solução trivial para o problema de ordenação é utilizar a probabilidade das previsões de um classificador como uma relação de ordem no conjunto a ser ordenado. De posse da previsão das classes dos elementos de um dado conjunto, basta ordená-los de forma crescente em função da probabilidade de cada um pertencer à classe $0$; os mais prováveis ocupam o topo, os menos prováveis ocupam o fundo.

Segundo \cite{langford08}, esse método para ordenação dos elementos pode resultar em um erro teórico máximo muito alto, dependendo da performance do classificador. A técnica de \emph{ranking reduzido a classificação}, proposta no mesmo artigo, reduz o erro teórico máximo envolvendo o treinamento do classificador com uma etapa de pré-processamento e a avaliação com uma etapa de pós-processamento.

Na técnica de \emph{ranking reduzido a classificação}, o treinamento do classificador ocorre pelo algoritmo \emph{AUC-Train} após uma etapa inicial em que se aplica uma transformação nos exemplos da base de treinamento. Após o treinamento, a definição da ordem das instâncias na base de avaliação é feita pelo algoritmo \emph{tournament} --- torneio em português --- que usa as previsões do classificador treinado para tal.

\section{Definições}

Como dito anteriormente, o treinamento e avaliação de um classificador é um processo que manipula conjuntos compostos por elementos. Definições mais rigorosas são necessárias para a descrição da implementação da técnica de \emph{ranking reduzido a classificação} no capítulo \ref{chap:implementacao}. As definições a seguir foram feitas levando-se em consideração o funcionamento da ferramenta WEKA e os requisitos necessários para se modelar a solução de \emph{ranking reduzido a classificação} exposta em \cite{langford08}.

\begin{itemize}
    \item Uma base $S$ é um conjunto de instâncias com cardinalidade $n$.
    \[S = \{i_1, ..., i_n\} \qquad |S| = n\]

    \item Uma instância $I$ é uma tupla $\langle x, y \rangle$ na qual $x$ é um vetor de atributos com cardinalidade $m$ e $y$ é a classe da instância e pode valer $0$ ou $1$.
    \[I = \langle x, y \rangle \qquad x = \{a_1, ..., a_m\} \qquad y \in \{0, 1\}\]
\end{itemize}

Pode-se acessar os atributos de uma instância $I$ através de $x_I$ e a classe através de $y_I$. Pode-se, também, concatenar os vetores de atributos de duas instâncias $I$ e $I'$ através da operação $(x_I, x_{I'})$.

Não será necessária a definição do conceito de atributo. Uma vez que os atributos são manipulados pelo classificador e o funcionamento dos classificadores nas soluções aqui propostas é uma caixa preta, os atributos são transparentes para os propósitos desse trabalho.

A tabela \ref{tab:weather} apresenta um exemplo de base extraído do livro \cite{wekabook}. Essa base indica se há condições para a prática de um esporte de acordo com medições meteorológicas. Um exemplo dessa base apresenta um conjunto de medições meteorológicas e, de acordo com essas medições, a classe do exemplo pode ser \emph{sim} ou \emph{não}.

\begin{table}[h!]
    \centering
    \begin{tabular}{ccccc}
        \hline
        panorama & temperatura & umidade & ventoso & adequado para jogo \\
        \hline
        ensolarado & quente & alta & falso & não \\
        ensolarado & quente & alta & verdadeiro & não \\
        nublado & quente & alta & falso & sim \\
        chuvoso & branda & alta & falso & sim \\
        chuvoso & frio & normal & falso & sim \\
        chuvoso & frio & normal & verdadeiro & não \\
        nublado & frio & normal & verdadeiro & sim \\
        ensolarado & branda & alta & falso & não \\
        ensolarado & frio & normal & falso & sim \\
        chuvoso & branda & normal & falso & sim \\
        ensolarado & branda & normal & verdadeiro & sim \\
        nublado & branda & alta & verdadeiro & sim \\
        nublado & quente & normal & falso & sim \\
        chuvoso & branda & alta & verdadeiro & não \\
        \hline
    \end{tabular}

    \caption{Base de dados de tempo. \label{tab:weather}}
\end{table}


A primeira linha nomeia os quatro atributos da base e a classe (adequado para jogo), as linhas seguintes representam as instâncias da base. Nota-se que a classe recebe valores \emph{sim} e \emph{não}, apesar de serem valores diferentes de $0$ e $1$, como dito na definição, ainda se trata de uma base com classe binária.

Escrevendo a primeira instância da base na notação definida anteriormente, tem-se: ((ensolarado, quente, alta, falso), não). O primeiro elemento da tupla é o vetor de atributos e o segundo elemento é a classe da instância.


\section{Medidas de desempenho}

Geralmente, a medida de eficiência mais utilizada para classificação é a acurácia: uma razão entre o número de instâncias corretamente classificadas sobre o número total de instâncias no conjunto de avaliação.

O erro decorrente de uma classificação afeta a acurácia de maneira linear. Como, para ordenações, a quantidade de acertos não é tão relevante quanto a posição das instâncias ordenadas, propõe-se outro tipo de medida para avaliação do \emph{ranking} aprendido.

Uma medida comum de avaliação para algoritmos de \emph{ranking} é a área sobre a curva \emph{ROC (Receiver Operating Characteristic)}, comumente chamada de \emph{AUC (Area Under the Curve)}.

A perda, $1 - AUC$, associada a essa medida é calculada pelo número de instâncias, normalizado pela quantidade de $0$s vezes a quantidade de $1$s, que necessitam ser trocadas para um \emph{ranking} perfeito.

Uma ordenação é perfeita quando todas as instâncias com classe $0$ precedem as com classe $1$, nesse caso a perda na \emph{AUC} é $0$. No pior caso, em que todos os $1$s precedem os $0$s, a perda na \emph{AUC} é $1$.

Comparativamente, um erro de classificação pode ter maior influência na medida \emph{AUC} que na acurácia afetando consideravelmente um \emph{ranking}, mas não a classificação. A causa disso é a \emph{AUC} considerar a relação entre as instâncias ordenadas, enquanto a acurácia considera apenas erros e acertos pontualmente. A seguir, ilustramos, através de um exemplo, uma relação entre essas medidas que comprova o intuído sobre erros na classificação.

\begin{table}[h!]
    \centering
    \begin{tabular}{cccccc}
        \hline
        panorama & temperatura & umidade & ventoso & classe & previsão \\
        \hline
        ensolarado & quente & alta & falso & não & sim \\
        nublado & quente & alta & falso & sim & sim \\
        chuvoso & branda & alta & falso & sim & sim \\
        chuvoso & frio & normal & falso & sim & sim \\
        nublado & frio & normal & verdadeiro & sim & sim \\
        ensolarado & frio & normal & falso & sim & sim \\
        chuvoso & branda & normal & falso & sim & sim \\
        ensolarado & branda & normal & verdadeiro & sim & sim \\
        nublado & branda & alta & verdadeiro & sim & sim \\
        nublado & quente & normal & falso & sim & sim \\
        ensolarado & quente & alta & verdadeiro & não & não \\
        chuvoso & frio & normal & verdadeiro & não & não \\
        ensolarado & branda & alta & falso & não & não \\
        chuvoso & branda & alta & verdadeiro & não & não \\
        \hline
    \end{tabular}

    \caption{Exemplo de \emph{ranking} e classificação na base weather.\label{tab:exemplo}}
\end{table}

Na tabela \ref{tab:exemplo}, temos quatorze instâncias ordenadas em um \emph{ranking} com os atributos, as classes e as previsões dadas por um classificador. Podemos perceber que o classificador errou apenas a classe da primeira instância. Calculando a acurácia, temos treze acertos em quatorze possíveis, o que equivale a aproximadamente $93\%$ de acerto.

Calculando a perda da AUC considerando como base a classe \emph{sim}, a primeira instância precisa retroceder nove posições para uma ordenação perfeita, normalizando pelo número de \emph{não's} vezes o número de \emph{sim's}, temos $(1 - AUC) = 9 \div (5 * 9) = 0,2$, logo a AUC vale $80\%$. Esse exemplo comprova que a AUC pode sofrer um impacto maior devido a erros de classificação se comparada à acurácia.

De acordo com \cite{langford08}, se um classificador gera um erro de ordem $\alpha$ na acurácia, ao ordenar uma base a partir das probabilidades das previsões desse classificador, o erro teórico máximo na AUC será de $\alpha \cdot n$, onde $n$ é a cardinalidade da base avaliada. Enquanto para o mesmo classificador, a técnica de \emph{ranking reduzido a classificação} apresenta um erro teórico máximo de $\alpha \cdot 2$.

O erro na AUC se intensifica a medida que o desbalanceamento de classes do conjunto usado no treinamento aumenta, pois quanto mais desbalanceadas as classes, mais provável que o classificador resultante seja tendencioso para a classe majoritária.
