Como dito anteriormente, a técnica de \emph{ranking reduzido a classificação} aplica uma transformação à base original antes da etapa de treinamento do classificador e modifica a etapa de avaliação a fim de ordenar as instâncias.

A transformação consiste em formar novas instâncias a partir de pares entre instâncias de classes diferentes. A ordem em que as instâncias aparecem no par é relevante, assim, se existe um par $\langle i_\alpha, i_\beta \rangle$, deve existir também um par $\langle i_\beta, i_\alpha \rangle$. Além disso, as classes das duas instâncias que formam um par são combinadas a fim de gerar uma nova classe para a nova instância.

Essa transformação foi implantada separando a base de treinamento em dois subconjuntos, um subconjunto $S_0$ com as instâncias de classe $0$ e outro, $S_1$, com as instâncias de classe $1$, e efetuando o produto cartesiano entre os dois conjuntos da seguinte maneira $S_r = (S_0 \times S_1) \cup (S_1 \times S_0)$.

Após a aplicação do produto cartesiano, uma instância da base resultante tem a forma $\langle (A_\alpha, C_\alpha), (A_\beta, C_\beta) \rangle$. As classes das duas instâncias devem ser combinadas em uma nova classe, isso se dá com o uso do operador $1$. Ao fim desse processo, uma instancia da nova base terá forma $\langle (A_\alpha, A_\beta), 1 \cdot (C_\alpha < C_\beta)$.

O operador $1$, aplicado para obter a classe da nova instância, retorna $1$, se o resultado da expressão avaliada é verdadeiro, ou $0$, se o resultado da expressão é falsa. Como o argumento para o operador é $C_\alpha < C_\beta$, se $C_\alpha$ valer $1$, a classe da nova instância será $0$, se valer $0$, a classe da nova instância será $1$. A transformação da base é o treinamento do classificador compõe um algoritmo de nome \emph{AUC-Train} (algoritmo \ref{alg:auc-train}).

\begin{algorithm}
    \begin{algorithmic}

        \STATE Let $S' = \{\langle (A_\alpha, A_\beta), 1 \cdot (C_\alpha < C_\beta) \rangle : (A_\alpha, C_\alpha), (x_\beta, y_\beta) \in S \wedge C_\alpha \neq C_\beta\}$
        \STATE return $c = A(S')$

        \caption{AUC-Train}
        \label{alg:auc-train}

    \end{algorithmic}
\end{algorithm}

A modificação da etapa de avaliação tem como objetivo usar as previsões do classificador treinado pelo \emph{AUC-Train} para gerar o \emph{ranking} da base de avaliação. O algoritmo que efetua a ordenação recebe o nome de \emph{Tournament}, torneio em português. O porquê do nome é devido a idéia do algoritmo se assemelhar muito a uma competição em que muitos competidores participam, formando um \emph{ranking} de acordo com suas performances.

Continuando a analogia com uma competição, a performance de cada instância na avaliação é medida como a quantidade de "vitórias" que essa instância obteve diante das outras instâncias na base de avaliação. Para gerar o \emph{ranking}, basta promover o embate entre todas as instâncias na base e ordenar pelo número de "vitórias".

Como desejamos ordenar as instâncias de forma que as que tenham maior chance de pertencer à classe $0$ estejam no topo, a semântica de "vitoria" é tal que, entre duas instâncias competindo, a instância vencedora tem maior chance de pertencer à classe $0$. Quem define a instância vitoriosa em um embate entre duas instâncias é a previsão do classificador binário.

Tecnicamente, um embate entre as instâncias $i_\alpha$ e $i_\beta$ consiste em criar uma nova instância com formato $\langle (A_\alpha, A_\beta)\rangle$ e submetê-la à classificação; se a classe prevista da nova instância for $1$, $i_\alpha$ ganha, se for $0$, $i_\beta$ ganha. Nota-se que o formato da instância a ser classificada é o mesmo que o de uma instância usada no treinamento do classificador, exceto pela ausência de classe. O algoritmo \ref{alg:tournament} demonstra o processo de ordenação.

\begin{algorithm}
    \begin{algorithmic}

        \FOR{$x \in U$}
            \STATE let $deg(x) = |\{x':c(x, x') = 1, x' \in U\}|$
        \ENDFOR

        \STATE Sort U in descending order of deg(x), breaking ties arbitrarily

        \caption{Tournament}
        \label{alg:tournament}

    \end{algorithmic}
\end{algorithm}

Uma das vantagens da técnica de \emph{ranking reduzido a classificação} é que o uso de um algoritmo de aprendizado para classificação é transparente. Essa característica possibilitou o uso dos algoritmos de classificação existentes na ferramenta \emph{WEKA}. Já um dos pontos negativos é a performance da técnica no que diz respeito a tempo.

O algoritmo \ref{alg:auc-train} executa duas etapas: na primeira, particiona-se a base de treinamento em duas bases $S_0$ e $S_1$; $S_0$ possui as instâncias de classe $0$ e $S_1$ possui as instâncias de classe $1$. Na segunda etapa, aplica-se o produto cartesiano duas vezes de forma que o conjunto de treinamento seja $S' = S_0 \times S_1 \cup S_1 \times S_0$.

Em questão de custo computacional, o tempo de execução do algoritmo \emph{AUC-Train} é composto pela soma dos tempos de particionamento da base de treinamento e da aplicação de dois produtos cartesianos. Para o estudo da complexidade do algoritmo considera-se uma base com $n$ instâncias das quais $k$ possuem a classe $0$ e $n - k$ possuem a classe $1$.

Para o particionamento da base, basta iterar uma vez pela base original incluindo as instâncias de classe $0$ no conjunto $S_0$ e as de classe $1$ no conjunto $S_1$. Essa etapa executa em tempo $O(n)$.

Após o particionamento da base, são executados os produtos cartesianos $S_0 \times S_1$ e $S_1 \times S_0$. O meio convencional de solucionar o produto cartesiano é aninhar dois \emph{loops} como mostrado no algoritmo \ref{alg:cross-product}.

Para o produto cartesiano, o melhor caso ocorre quando $k = 0$ ou $k = n$, nesses casos todas as instâncias pertencem à mesma classe; dessa forma, o produto cartesiano não executa os loops e o tempo computacional é $O(1)$.

No caso médio, parte-se da hipótese que todas as entradas são uniformemente prováveis. A probabilidade de uma entrada para um dado $k$ é $\frac{1}{n}$ e a quantidade de iterações geradas por essa entrada é $k \cdot (n - k)$. Partindo desses dados, a complexidade do caso médio pode ser calculada pela fórmula $O(f_{avg}(n))$, na qual:

\[f_{avg}(n) = \sum_{k = 0}^{n} \frac{k \cdot (n - k)}{n}\]

Desenvolvendo o somatório:

\begin{align*}
    f_{avg}(n) &= \frac{1}{n} \cdot \sum_{k = 0}^{n} k(n - k) \\
               &= \frac{1}{n} \cdot \sum_{k = 0}^{n} kn - k^2 \\
               &= \frac{1}{n} \cdot \left(\sum_{k = 0}^{n} kn - \sum_{k = 0}^{n} k^2\right) \\
               &= \frac{1}{n} \cdot \left(n \cdot \sum_{k = 1}^{n} k - \sum_{k = 1}^{n} k^2\right) \\
               &= \frac{1}{n} \cdot \left(n \cdot \frac{n(n + 1)}{2} - \frac{n(n + 1)(2n + 1)}{6}\right) \\
               &= \frac{1}{n} \cdot \frac{n^3 + n}{6} = \frac{n^2 -1}{6}
\end{align*}

Logo, o caso médio é igual a $O(f_{avg}) = O(\frac{n^2 -1}{6}) = O(n^2)$.

O pior caso acontece quando $k = \frac{n}{2}$, nesse caso a base de treinamento possui metade das instâncias com classe $0$ e a outra metade com classe $1$. O produto cartesiano ocorrerá em dois conjuntos com $\frac{n}{2}$ instâncias, resultando na complexidade assintótica $O(\frac{n}{2} \cdot \frac{n}{2}) = O(\frac{n^2}{4}) = O(n^2)$.

\begin{table}[h]
    \centering
    \begin{tabular}{ c | c c | c }
        \hline

        Caso & Particionamento & Produto Cartesiano & AUC-Train \\

        \hline

        Melhor & $O(n)$ & $O(1)$ & $O(n) + O(1) = O(n)$ \\
        Médio & $O(n)$ & $O(n^2)$ & $O(n) + O(n^2) = O(n^2)$ \\
        Pior  & $O(n)$ & $O(n^2)$ & $O(n) + O(n^2) = O(n^2)$ \\
    
        \hline
    \end{tabular}

    \caption{Complexidade do algoritmo AUC-Train}
    \label{j48_results_table}
\end{table}

Algumas otimizações podem e foram aplicadas no algoritmo final escrito em \emph{Java} para o \emph{workbench WEKA}, por exemplo: o algoritmo de produto cartesiano é levemente alterado para gerar tanto o par $(x, y)$ quanto o par $(y, x)$, isso evita a necessidade de aplicar duas vezes o produto cartesiano; o uso do operador $1$ está embutido no algoritmo de produto cartesiano e não acrescenta complexidade extra ao algoritmo, entre outras. Apesar da aplicação dessas otimizações, a complexidade assintótica do algoritmo continua inalterada.

\begin{algorithm}
    \begin{algorithmic}
        \STATE $S \gets \emptyset$

        \FOR{$x \in S_1$}
            \FOR{$y \in S_2$}
                \STATE $S \gets S \cup \{(x, y)\}$
            \ENDFOR
        \ENDFOR

        \STATE returns S

        \caption{Cross Product}
        \label{alg:cross-product}

    \end{algorithmic}
\end{algorithm}

Para o algoritmo de torneio, o pior caso, o caso médio e o melhor caso apresentam o mesmo tempo de execução, pois é sempre necessário formar todos os pares de instâncias possíveis a fim de obter a ordem de todas as instâncias. Como mostrado no algoritmo \ref{alg:tournament}, a operação de gerar todos os pares aninha dois \emph{loops}o que resulta em um custo de ordem $O(n^2)$, onde $n$ é o tamanho da base a ser ordenada.

Tanto o algoritmo \emph{AUC-Train} quanto o \emph{Tournament} apresentam tempos elevados de execução. A prática de comparar as instâncias em pares onera tanto os processos de treinamento e de ordenação e, usando bases extensas, o tempo de execução do algoritmo degrada consideravelmente. Essa característica levou à busca de alternativas para tornar ambos treinamento e ordenação mais rápidos.

Duas abordagens foram consideradas para amortizar a complexidade do algoritmo: uma para a fase de treinamento e outra para a fase de geração do \emph{ranking}. Para a fase de classificação, foi pensada uma estratégia de amostragem da base original e votação entre classificadores e para a geração do \emph{ranking}, foi pensada uma estratégia de torneio baseada em \emph{quicksort}.

\section{Otimização do treinamento: Amostragem e Votação}
O algoritmo original chama a etapa de treinamento de AUC-Train. Nessa etapa, são feitas combinações entre as instâncias de classe $0$ e de classe $1$, como mostrado no \emph{algoritmo \ref{alg:auc-train}}.

Esse algoritmo de mesclagem das instâncias é executado uma vez e seu resultado é usado como massa de dados para um algoritmo de aprendizado; no caso específico dessa implantação, um classificador.

O custo total do AUC-Train é composto pelos custos da etapa de mesclagem e do algoritmo de aprendizagem somados. Vale ressaltar que a etapa de mesclagem tem um tempo maior de execução; a otimização endereça esse problema especificamente.

Na estratégia adotada para reduzir o tempo de mesclagem figuram duas técnicas conhecidas em \emph{data mining}, a primeira é efetuar uma amostragem do conjunto original e a segunda é promover uma votação entre vários classificadores treinados com as amostragens como massa de dados.

\begin{algorithm}
\begin{algorithmic}

\STATE Let $S_0 = \{\langle (x, y) \rangle: (x, y) \in S \wedge y = 0\}$
\STATE Let $S_1\,=\,S\,-\,S_0$

\STATE $V\,\gets\,\emptyset$

\FOR{$i\,=\,1,\;i\,\to\,iterations$}
\STATE Let $S_{sample} = S' : S' \subset S_1 \wedge |S'| = limit$
\STATE Let $S_{train} = \{\langle ((x_{0},\,x_{s}),\, 1),\; ((x_{s},\, x_{0}),\,0) \rangle:
       (x_{0},\,y_{0})\,\in\,S_{0}\,\wedge\,
       (x_{s},\,y_{s})\,\in\,S_{sample}\}$
\STATE $c\,\gets\,A(S_{train})$
\STATE $V\,\gets\,V\,\bigcup\,\{c\}$
\ENDFOR

\caption{AUC-Train com amostragem}
\label{alg:auc-train-amostragem-votacao}

\end{algorithmic}
\end{algorithm}

O produto gerado pelo algoritmo \ref{alg:auc-train-amostragem-votacao} é um conjunto de classificadores treinados a partir de amostragens do conjunto original. Se passarmos os parâmetros $limit=all$ e $iterations=1$, ele gera o mesmo resultado do algortimo descrito por {{langford}}.


\section{Otimização da ordenação: Quicksort}
A etapa de ordenação original é chamada de \emph{torneio}. Nessa abordagem, todas as instâncias do conjunto a ser ordenado são comparadas entre si com base no classificador obtido no treinamento e recebem uma pontuação. As instâncias de maior pontuação assumem as primeiras posições no \emph{ranking}. A proposta de otimização baseia-se em uma adaptação do algoritmo de quicksort para ordenar as instâncias do \emph{ranking}.

\begin{algorithm}
\begin{algorithmic}

\FORALL{$x\,\in\,U$}
\STATE $deg(x) = |\{x': c(x, x')=1, x'\in U\}|$
\ENDFOR
\STATE Ordene U de forma descendente com base em $deg(x)$, resolva os empates arbitrariamente

\caption{Degree}
\label{alg:degree}

\end{algorithmic}
\end{algorithm}


\section{Definições}
Algumas definições necessárias para o funcionamento do algoritmo final.

\section{Algoritmo final}

\begin{algorithm}
\begin{algorithmic}

\STATE $c \gets train(TS, LA, pairs, iterations)$
\STATE $rank(RS, c, quicksort)$

\caption{Algoritmo final do \emph{Ranking}}
\label{alg:ranking}

\end{algorithmic}
\end{algorithm}
